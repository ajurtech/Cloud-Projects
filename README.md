## Introduction

This repository provides an overview of various cloud computing projects that I have worked on, utilizing my skills in AWS, Azure and other cloud technologies. These projects demonstrate practical solutions involving cloud infrastructure, automation, and hybrid cloud integration, emphasizing real-world impact and technical efficiency. 

To explore these projects in-depth visit my GitHub repository: 
[https://github.com/ajurtech](https://github.com/ajurtech). 

## Projects Overview

### 1. Secure Deployment of CharityConnect Web Application
- **Description**: Developed a cloud-based platform for charities using Jenkins for CI/CD, Terraform for infrastructure as code and AWS (EC2, S3).
- **Security**: Integrated OWASP Sonarqube to ensure security best practices were followed throughout the development lifecycle.
- **Features**: Implemented functionalities such as user registration, catalog browsing, shopping cart and order management, with automated deployment pipelines using Jenkins and Terraform.

### 2. Development of E-Commerce Marketplace: FabricConnect
- **Description**: Created an e-commerce platform linking designers with local suppliers using AWS services like Cloud9, EC2, S3, Lambda, and CloudWatch.
- **Objective**: Aimed to reduce global supply chain reliance and lower carbon emissions by providing a platform for local suppliers and designers in Ireland to connect easily.
- **Technical Stack**: Utilized AWS Cloud9 for development, Django for the backend, and AWS S3 for media storage. Integrated AWS SNS and SQS for notifications and messaging. Deployed using AWS Elastic Beanstalk and managed continuous deployment through AWS CodePipeline.
- **Functionality**: The platform enables designers to browse raw material catalogs, manage shopping carts, and make purchases. Suppliers can list products with images and details, while AWS SNS provides email notifications for new releases.
- **Architecture**: Leveraged Django's Model-View-Template (MVT) structure for efficient development and AWS services for scalable infrastructure. The application follows cloud-native best practices to ensure reliability and sustainability.

### 3. Scalable Cloud Programming with Apache Hadoop and Spark
- **Description**: Designed a scalable solution for processing large datasets using Apache Hadoop and Apache Spark.
- **Objective**: To leverage distributed computing to efficiently handle and analyze massive datasets using Hadoop HDFS and Apache Spark.
- **Technical Stack**: Hadoop HDFS was used for storage, while Apache Spark was utilized for in-memory data processing to outperform traditional MapReduce.
- **Functionality**: Implemented data storage and processing using HDFS for large data collections. Configured a single-node Hadoop cluster, used Spark's DataFrame API for in-memory data analysis and conducted analytics on CRAN package download logs.

### 4. Effective Patient Oxygen Monitoring System Using Fog Computing
- **Description**: Developed a fog-based architecture for monitoring oxygen levels in hospitals to optimize the availability and reduce latency in healthcare services.
- **Objective**: To enhance real-time patient oxygen monitoring using a fog computing solution for better response and reduced latency compared to cloud-based systems.
- **Technical Stack**: iFogSim for simulations, fog nodes for local processing, and cloud integration for centralized data storage.
- **Functionality**: Created a multi-tier architecture using fog nodes to handle real-time data from medical devices, reducing the dependency on centralized cloud resources and ensuring faster decision-making.
- **Impact**: Demonstrated reduced network consumption and latency, proving fog-based architecture is more suitable for real-time healthcare applications.

### 5. Dublin Property Price Prediction Using Machine Learning
- **Description**: Built a machine learning model to predict property prices in Dublin using historical transaction data.
- **Objective**: To provide predictive insights into property values using machine learning algorithms such as Random Forest, SVM, and XGBoost.
- **Technical Stack**: AWS SageMaker for model training, Python for data preprocessing and Elastic Beanstalk for deployment.
- **Functionality**: Collected data from the Irish Property Price Register, applied preprocessing, feature engineering, and trained multiple models to predict property prices. The final model was deployed on AWS SageMaker and integrated with a front-end web app for user interaction.

## Technical Skills

- **Solution Architecture**: Cloud and on-premises integration, multi-domain architecture alignment, SDLC management
- **Cloud Services**:
  - **AWS**: EC2, S3, Lambda, CloudWatch, SageMaker, Elastic Beanstalk, Cloud9, SNS, SQS.
  - **Azure**: Azure Active Directory, Security Center, Virtual Machines, Load Balancing.
- **Automation & DevOps**: Jenkins (CI/CD), Terraform, AWS CodePipeline, PowerShell scripting.
- **Web Frameworks**: Django (Python), Red Hat OpenShift for containerization.
- **Big Data & Machine Learning**: Hadoop, Apache Spark, AWS SageMaker, Random Forest, SVM, XGBoost.
- **Systems Integration**: On-premises and SaaS solution integration on AWS and Azure.
- **Languages & Tools**: Python, PowerShell, Terraform, Jenkins, Ansible, VMware, Hyper-V, HTML, CSS, JavaScript.

## Contact Information

- **GitHub**: [ajurdude/cloud-projects](https://github.com/ajurtech)
- **LinkedIn**: [linkedin.com/in/arjunjadhav](https://www.linkedin.com/in/arjunjadhav)
- **Email**: [Arjunjadhav1993@outlook.com](mailto\:Arjunjadhav1993@outlook.com)

Feel free to explore the projects and reach out if you have any questions or collaboration ideas.

